{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de severidad de accidentes de tránsito\n",
    "\n",
    "\n",
    "\n",
    "1.   Tenemos un archivo con datos: train.csv el cual contiene información sobre accidentes de tránsito en EEUU y un archivo test4alumnxs.csv que tiene la misma info pero sin las etiquetas para Severity (más información abajo).\n",
    "2.   El objetivo es usar los datos para construir un modelo que prediga la severidad del accidente (columna 'Severity', donde 0 es baja severidad y 1 es alta severidad). Para esto, primero puedo usar los datos del archivo train.csv para ajustar los parámetros del modelo, ajustar los hiperparámetros, combinar los features para agregar nuevos, estandarizar los datos, etc. Al terminar esto, tendré un modelo entrenado en estos datos, y una idea de que tan bien funciona. Luego generaremos un vector de probabilidades sobre el test4alumnos.csv para tratar de predecir la severidad del accidente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9ADQN0ETpKJ"
   },
   "source": [
    "# Los datos\n",
    "Los datos corresponden a registros de accidentes de tránsito en EEUU entre 2016 y 2021.\n",
    "\n",
    "Las primeras dos columnas (\"unnamed\") no sirve nara nada y se pueden descartar. \n",
    "\n",
    "La columna 'Severity' contiene la severidad del accidente (0 significa baja, 1 significa alta)\n",
    "\n",
    "Luego tenemos la hora de comienzo y final del accidente, la latitud/longitud inicial y final del accidente (entre que valores queda delimitado), la distancia de camino afectada por el accidente, una descripción verbal hecha por un humano, número y nombre de la calle donde ocurrió, lado de la calle (izquierda o derecha), ciudad, condado, estado, código postal, huso horario, código de aeropuerto donde se encuentra la estación meterológica más cercana al accidente, hora en la cual se midió el clima,temperatura, temperatura del viento, humedad, presión, visibilidad, dirección del viento, condición climática (despejado, sol, nieve, etc), presencia de comodidades (\"amenities\") en la cercanía del accidente, presencia de loma de burro, presencia de un cruce, presencia de señal de ceder paso, presencia de unión de calles, presencia de cartel de no salida, presencia de vías de tren, presencia de rotonda, presencia de estación, presencia de signo de parar, presencia de moderadores de tráfico, presencia de señales de tránsito, presencia de calle en forma de U (\"loop\"), día u oscuridad de acuerdo a la salida del sol, día u oscuridad de acuerdo a la penumbra civil (si es o no necesario utilizar alumbramiento eléctrico), día u oscuridad de acuerdo a la penumbra náutica, día u oscuridad de acuerdo a la penumbra astronómica.\n",
    "\n",
    "No todos estos campos son necesariamente útiles, y tampoco no todos están en un formato numérico directamente utilizable (por ejemplo, hay strings en la parte de descripción del accidente). Será parte del trabajo decidir que features quedarse, que features sumar, y como extraer información relevante de los features más complejos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4YgPyZuLQ3T",
    "outputId": "f38c8d1c-35e1-46eb-f5a8-f24d243d9ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Start_Time', 'End_Time', 'Start_Lat',\n",
       "       'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Description',\n",
       "       'Number', 'Street', 'Side', 'City', 'County', 'State', 'Zipcode',\n",
       "       'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp',\n",
       "       'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
       "       'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n",
       "       'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
       "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
       "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
       "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
       "       'Astronomical_Twilight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "drive.mount('/content/drive') # montamos el drive\n",
    "\n",
    "# cargamos el dataframe de entrenamiento y el dataframe de testeo\n",
    "# el dataframe de entrenamiento tiene toda la información, incluyendo la columna 'Severity' (severidad)\n",
    "# esta es la columna que vamos a entrenar el modelo para predecir: 0=severidad baja; 1=severidad alta.\n",
    "# en cambio, el dataframe de test no tiene esta columna: son los datos que usamos para generar la predicción que se entrega \n",
    "filename_train = '/content/drive/My Drive/LaboDatos2022/SegundaEjercitacion/train.csv' \n",
    "filename_test = '/content/drive/My Drive/LaboDatos2022/SegundaEjercitacion/test4alumnxs.csv' \n",
    "\n",
    "df_train = pd.read_csv(filename_train)\n",
    "df_test = pd.read_csv(filename_test)\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXWCS2FzY_SV",
    "outputId": "21ff2ec4-79ad-4b3d-8167-2af55960c284"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Severity', 'Start_Time', 'End_Time',\n",
       "       'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)',\n",
       "       'Description', 'Number', 'Street', 'Side', 'City', 'County', 'State',\n",
       "       'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp',\n",
       "       'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
       "       'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n",
       "       'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
       "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
       "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
       "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
       "       'Astronomical_Twilight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XP2_ICKMVGqZ",
    "outputId": "e7fca806-f7b5-49de-b2d7-837828bb55eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28072\n",
       "1    17762\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Severity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como el dataset no parece tener un desbalance importante, sigo adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCSubQOJ_hpP",
    "outputId": "5fbfbd4a-417b-4a0f-b2fb-922c82025830"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fair                           21874\n",
       "Cloudy                          7202\n",
       "Mostly Cloudy                   5689\n",
       "Partly Cloudy                   3998\n",
       "Light Rain                      2103\n",
       "Fog                              871\n",
       "Light Snow                       809\n",
       "Rain                             420\n",
       "Haze                             419\n",
       "Fair / Windy                     344\n",
       "Overcast                         219\n",
       "Smoke                            199\n",
       "Heavy Rain                       175\n",
       "Thunder in the Vicinity          156\n",
       "Cloudy / Windy                   137\n",
       "Light Drizzle                    128\n",
       "T-Storm                          124\n",
       "Mostly Cloudy / Windy            114\n",
       "Snow                             113\n",
       "Thunder                          110\n",
       "Light Rain with Thunder           95\n",
       "Wintry Mix                        74\n",
       "Light Rain / Windy                69\n",
       "Partly Cloudy / Windy             69\n",
       "Heavy T-Storm                     56\n",
       "Drizzle                           46\n",
       "Light Snow / Windy                32\n",
       "Heavy Snow                        26\n",
       "Light Freezing Rain               13\n",
       "Clear                             12\n",
       "Haze / Windy                      12\n",
       "Shallow Fog                       10\n",
       "Mist                               9\n",
       "Rain / Windy                       9\n",
       "Patches of Fog                     8\n",
       "N/A Precipitation                  8\n",
       "Showers in the Vicinity            8\n",
       "Blowing Snow                       7\n",
       "Heavy Rain / Windy                 7\n",
       "Smoke / Windy                      7\n",
       "Snow / Windy                       5\n",
       "Light Drizzle / Windy              5\n",
       "Fog / Windy                        5\n",
       "Scattered Clouds                   4\n",
       "Thunder / Windy                    4\n",
       "Heavy T-Storm / Windy              3\n",
       "Light Freezing Drizzle             3\n",
       "Drizzle and Fog                    3\n",
       "Heavy Drizzle                      2\n",
       "Blowing Dust / Windy               2\n",
       "Heavy Snow / Windy                 2\n",
       "Light Ice Pellets                  2\n",
       "Light Freezing Fog                 2\n",
       "Light Freezing Rain / Windy        2\n",
       "Squalls / Windy                    2\n",
       "Widespread Dust / Windy            2\n",
       "Light Rain Shower                  2\n",
       "Light Snow and Sleet               1\n",
       "Sand / Dust Whirlwinds             1\n",
       "Light Blowing Snow                 1\n",
       "Name: Weather_Condition, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Weather_Condition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9fdBIBu15Gb",
    "outputId": "54e28285-0502-43f6-cb08-36cf67740d2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Severity', 'Start_Time', 'End_Time',\n",
       "       'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)',\n",
       "       'Description', 'Number', 'Street', 'Side', 'City', 'County', 'State',\n",
       "       'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp',\n",
       "       'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
       "       'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n",
       "       'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
       "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
       "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
       "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
       "       'Astronomical_Twilight', 'Highway_or_road', 'Serious', 'Night',\n",
       "       'Adverse_Weather'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrego algunas columnas a train.csv y a test4alumnxs.csv para testear mis hipótesis:\n",
    "# 1) Los accidentes más severos son los que se producen en autopistas o carreteras de alta velocidad (por ejemplo, rutas nacionales).\n",
    "# 2) Los accidentes más severos contienen una advertencia del tipo \"blocked\", \"multi\" o \"closed road\" (u otras)\n",
    "# 3) Los accidentes más severos se producen de noche.\n",
    "# 4) Los accidentes más severos se producen en condiciones climatológicas desfavorables (lluvia, nieve, niebla, etc).\n",
    "def highway_or_road(a):\n",
    "    if \"highway\" in a.lower():\n",
    "        return True\n",
    "    elif \"hwy\" in a.lower():\n",
    "        return True\n",
    "    elif \"road\" in a.lower():\n",
    "      return True\n",
    "    elif \"rd\" in a.lower():\n",
    "      return True\n",
    "    elif \"route\" in a.lower():\n",
    "      return True\n",
    "    else:\n",
    "        return False\n",
    "df_train[\"Highway_or_road\"] = df_train[\"Street\"].apply(lambda x: highway_or_road(x))\n",
    "df_test[\"Highway_or_road\"] = df_test[\"Street\"].apply(lambda x: highway_or_road(x))\n",
    "\n",
    "def serious(a):\n",
    "    #if \"drive with caution\" in a.lower():\n",
    "        #return True\n",
    "    if \"closed\" in a.lower():\n",
    "        return True\n",
    "    elif \"blocked\" in a.lower():\n",
    "      return True\n",
    "    elif \"closure\" in a.lower():\n",
    "      return True\n",
    "    elif \"multi\" in a.lower():\n",
    "      return True\n",
    "    elif \"serious\" in a.lower():\n",
    "      return True\n",
    "    else:\n",
    "        return False\n",
    "df_train[\"Serious\"] = df_train[\"Description\"].apply(lambda x: serious(x))\n",
    "df_test[\"Serious\"] = df_test[\"Description\"].apply(lambda x: serious(x))\n",
    "\n",
    "def night(a):\n",
    "  if \"Night\" in a.lower():\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "df_train[\"Night\"] = df_train[\"Civil_Twilight\"].apply(lambda x: night(x))\n",
    "df_test[\"Night\"] = df_test[\"Civil_Twilight\"].apply(lambda x: night(x))\n",
    "\n",
    "def adverse_weather(a):\n",
    "  if \"rain\" in a.lower():\n",
    "    return True\n",
    "  elif \"snow\" in a.lower():\n",
    "    return True\n",
    "  elif \"fog\" in a.lower():\n",
    "    return True\n",
    "  elif \"smoke\" in a.lower():\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "df_train[\"Adverse_Weather\"] = df_train[\"Weather_Condition\"].apply(lambda x: adverse_weather(x))\n",
    "df_test[\"Adverse_Weather\"] = df_test[\"Weather_Condition\"].apply(lambda x: adverse_weather(x))\n",
    "\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOovUCx56wYH",
    "outputId": "f6e818b7-b5fb-40ba-c9ef-98ca26af923d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Start_Time', 'End_Time', 'Start_Lat',\n",
       "       'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Description',\n",
       "       'Number', 'Street', 'Side', 'City', 'County', 'State', 'Zipcode',\n",
       "       'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp',\n",
       "       'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
       "       'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n",
       "       'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
       "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
       "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
       "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
       "       'Astronomical_Twilight', 'Highway_or_road', 'Serious', 'Night',\n",
       "       'Adverse_Weather'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHJKbQHB64R-",
    "outputId": "493262c8-5a17-4cdd-cba5-7ca8cecf5b0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11372, 51)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "id": "6EWy_VCgEN-W",
    "outputId": "37d999e7-8144-4760-d451-7f6cd7b1a0b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-34d9d01b-92a4-45ec-bc7f-65d5a83a83f7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "      <th>Highway_or_road</th>\n",
       "      <th>Serious</th>\n",
       "      <th>Night</th>\n",
       "      <th>Adverse_Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-19 23:58:30.000000000</td>\n",
       "      <td>2021-08-20 00:36:30.000000000</td>\n",
       "      <td>35.879641</td>\n",
       "      <td>-78.734582</td>\n",
       "      <td>35.884381</td>\n",
       "      <td>-78.740822</td>\n",
       "      <td>0.479</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-28 21:09:00.000000000</td>\n",
       "      <td>2021-01-29 01:18:47.000000000</td>\n",
       "      <td>36.206389</td>\n",
       "      <td>-121.116768</td>\n",
       "      <td>36.206635</td>\n",
       "      <td>-121.116980</td>\n",
       "      <td>0.021</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-12 04:48:00</td>\n",
       "      <td>2021-02-12 06:26:21</td>\n",
       "      <td>30.499754</td>\n",
       "      <td>-91.138325</td>\n",
       "      <td>30.499795</td>\n",
       "      <td>-91.136996</td>\n",
       "      <td>0.079</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-09 13:25:30</td>\n",
       "      <td>2020-12-10 00:19:49</td>\n",
       "      <td>26.548679</td>\n",
       "      <td>-81.871670</td>\n",
       "      <td>26.546193</td>\n",
       "      <td>-81.871104</td>\n",
       "      <td>0.175</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-30 16:30:18</td>\n",
       "      <td>2020-10-30 17:45:26</td>\n",
       "      <td>45.533651</td>\n",
       "      <td>-94.100321</td>\n",
       "      <td>45.532940</td>\n",
       "      <td>-94.099488</td>\n",
       "      <td>0.064</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45829</th>\n",
       "      <td>159985</td>\n",
       "      <td>159985</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11 16:44:04</td>\n",
       "      <td>2020-05-11 17:12:48</td>\n",
       "      <td>35.656480</td>\n",
       "      <td>-118.444170</td>\n",
       "      <td>35.656830</td>\n",
       "      <td>-118.440450</td>\n",
       "      <td>0.210</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45830</th>\n",
       "      <td>159987</td>\n",
       "      <td>159987</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-05 03:57:02</td>\n",
       "      <td>2018-12-05 04:26:27</td>\n",
       "      <td>39.492480</td>\n",
       "      <td>-84.131800</td>\n",
       "      <td>39.517181</td>\n",
       "      <td>-84.098369</td>\n",
       "      <td>2.468</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45831</th>\n",
       "      <td>159991</td>\n",
       "      <td>159991</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-02 03:13:00</td>\n",
       "      <td>2020-12-02 08:05:55</td>\n",
       "      <td>41.158851</td>\n",
       "      <td>-79.396466</td>\n",
       "      <td>41.172221</td>\n",
       "      <td>-79.399466</td>\n",
       "      <td>0.937</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45832</th>\n",
       "      <td>159992</td>\n",
       "      <td>159992</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-10 10:16:56</td>\n",
       "      <td>2019-09-10 10:45:23</td>\n",
       "      <td>30.287466</td>\n",
       "      <td>-81.720190</td>\n",
       "      <td>30.288360</td>\n",
       "      <td>-81.720190</td>\n",
       "      <td>0.062</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45833</th>\n",
       "      <td>159995</td>\n",
       "      <td>159995</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-30 19:55:00</td>\n",
       "      <td>2021-03-30 21:22:41</td>\n",
       "      <td>40.310321</td>\n",
       "      <td>-79.600672</td>\n",
       "      <td>40.311191</td>\n",
       "      <td>-79.606673</td>\n",
       "      <td>0.322</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45834 rows × 52 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34d9d01b-92a4-45ec-bc7f-65d5a83a83f7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-34d9d01b-92a4-45ec-bc7f-65d5a83a83f7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-34d9d01b-92a4-45ec-bc7f-65d5a83a83f7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  Severity                     Start_Time  \\\n",
       "0               2             2         0  2021-08-19 23:58:30.000000000   \n",
       "1               7             7         0  2021-01-28 21:09:00.000000000   \n",
       "2              11            11         0            2021-02-12 04:48:00   \n",
       "3              12            12         0            2020-12-09 13:25:30   \n",
       "4              13            13         0            2020-10-30 16:30:18   \n",
       "...           ...           ...       ...                            ...   \n",
       "45829      159985        159985         1            2020-05-11 16:44:04   \n",
       "45830      159987        159987         1            2018-12-05 03:57:02   \n",
       "45831      159991        159991         1            2020-12-02 03:13:00   \n",
       "45832      159992        159992         1            2019-09-10 10:16:56   \n",
       "45833      159995        159995         1            2021-03-30 19:55:00   \n",
       "\n",
       "                            End_Time  Start_Lat   Start_Lng    End_Lat  \\\n",
       "0      2021-08-20 00:36:30.000000000  35.879641  -78.734582  35.884381   \n",
       "1      2021-01-29 01:18:47.000000000  36.206389 -121.116768  36.206635   \n",
       "2                2021-02-12 06:26:21  30.499754  -91.138325  30.499795   \n",
       "3                2020-12-10 00:19:49  26.548679  -81.871670  26.546193   \n",
       "4                2020-10-30 17:45:26  45.533651  -94.100321  45.532940   \n",
       "...                              ...        ...         ...        ...   \n",
       "45829            2020-05-11 17:12:48  35.656480 -118.444170  35.656830   \n",
       "45830            2018-12-05 04:26:27  39.492480  -84.131800  39.517181   \n",
       "45831            2020-12-02 08:05:55  41.158851  -79.396466  41.172221   \n",
       "45832            2019-09-10 10:45:23  30.287466  -81.720190  30.288360   \n",
       "45833            2021-03-30 21:22:41  40.310321  -79.600672  40.311191   \n",
       "\n",
       "          End_Lng  Distance(mi)  ... Traffic_Signal  Turning_Loop  \\\n",
       "0      -78.740822         0.479  ...          False         False   \n",
       "1     -121.116980         0.021  ...          False         False   \n",
       "2      -91.136996         0.079  ...          False         False   \n",
       "3      -81.871104         0.175  ...          False         False   \n",
       "4      -94.099488         0.064  ...          False         False   \n",
       "...           ...           ...  ...            ...           ...   \n",
       "45829 -118.440450         0.210  ...          False         False   \n",
       "45830  -84.098369         2.468  ...          False         False   \n",
       "45831  -79.399466         0.937  ...          False         False   \n",
       "45832  -81.720190         0.062  ...          False         False   \n",
       "45833  -79.606673         0.322  ...          False         False   \n",
       "\n",
       "      Sunrise_Sunset Civil_Twilight Nautical_Twilight Astronomical_Twilight  \\\n",
       "0              Night          Night             Night                 Night   \n",
       "1              Night          Night             Night                 Night   \n",
       "2              Night          Night             Night                 Night   \n",
       "3                Day            Day               Day                   Day   \n",
       "4                Day            Day               Day                   Day   \n",
       "...              ...            ...               ...                   ...   \n",
       "45829            Day            Day               Day                   Day   \n",
       "45830          Night          Night             Night                 Night   \n",
       "45831          Night          Night             Night                 Night   \n",
       "45832            Day            Day               Day                   Day   \n",
       "45833          Night            Day               Day                   Day   \n",
       "\n",
       "      Highway_or_road Serious  Night Adverse_Weather  \n",
       "0               False   False  False            True  \n",
       "1               False   False  False            True  \n",
       "2               False   False  False            True  \n",
       "3               False   False  False           False  \n",
       "4                True   False  False           False  \n",
       "...               ...     ...    ...             ...  \n",
       "45829            True    True  False           False  \n",
       "45830            True    True  False            True  \n",
       "45831            True    True  False           False  \n",
       "45832           False    True  False           False  \n",
       "45833            True    True  False           False  \n",
       "\n",
       "[45834 rows x 52 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z83OloICT0Ug"
   },
   "source": [
    "Luego, sacamos el vector de etiquetas (severidad).\n",
    "\n",
    "En este modelo vamos a usar el subconjunto de features que corresponde a variables climáticas: temperatura, temperatura del viento, humedad, presión, visibilidad, velocidad del viento y precipitación así como otras correspondientes al contexto del accidente (si era un cruce de calles, si ocurrió en autopista, si el clima era adverso, etc.).\n",
    "\n",
    "Con esto armamos la matriz X. Luego, separamos un 70%/30% para train y test del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWiWcD7eLtT-"
   },
   "outputs": [],
   "source": [
    "y = np.array(df_train['Severity']) # armo el vector de etiquetas\n",
    "\n",
    "# vamos a entrenar un modelo con estas variables\n",
    "columnas = ['Temperature(F)', 'Wind_Chill(F)', 'Distance(mi)', 'Stop', 'Humidity(%)','Junction','Crossing', \"Highway_or_road\", \"Serious\", \"Night\", \"Adverse_Weather\",'Traffic_Signal', 'Traffic_Calming','Pressure(in)','Visibility(mi)','Wind_Speed(mph)','Precipitation(in)']\n",
    "\n",
    "# extraigo la matriz de features X\n",
    "X = np.array(df_train[columnas])\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2MyvbDWW6KQ",
    "outputId": "c594cd28-b59b-4868-c5ef-2530ae0b6dc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999877545112356, 0.9758308960573187)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pruebo con un random forest así como viene de fábrica\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                             max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, \n",
    "                             random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)  \n",
    "\n",
    "# ajusto el modelo\n",
    "clf_rf.fit(X_train, y_train) #Como veo que es el mejor modelo, lo nombro de diferente manera así puedo luego armar el vector de etiquetas.\n",
    "\n",
    "# armo el vector de predicciones.\n",
    "y_hat_test = clf_rf.predict_proba(X_test)[:, 1]\n",
    "y_hat_train = clf_rf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# evaluo el AUC\n",
    "roc_test = roc_auc_score(y_test, y_hat_test)\n",
    "roc_train = roc_auc_score(y_train, y_hat_train)\n",
    "roc_train, roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atvDe3ppYMdz",
    "outputId": "556c7221-3bb0-4f68-9f15-718cc8168be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estos son los valores AUC para cada fold:\n",
      "[0.9716992621517332, 0.9744444076757078, 0.9760936507190069, 0.9777392492392917, 0.9742788048780879]\n",
      "Estos es el promedio de todos los AUC:\n",
      "0.9748510749327656\n",
      "Estos son las probabilidades para cada sample:\n",
      "[0.02 0.02 0.   ... 0.96 0.96 1.  ]\n",
      "Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\n",
      "[0.0000e+00 9.0000e+00 1.2000e+01 ... 4.5825e+04 4.5829e+04 4.5831e+04]\n"
     ]
    }
   ],
   "source": [
    "auc_values = [] # aca es donde van a ir a parar los AUCs de cada fold\n",
    "scores = np.array([])     # aca es donde van a ir a parar los scores computados para todos los casos\n",
    "indices = np.array([])    # aca es donde van a ir a parar los indices correspondientes a las entradas de scores\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5, shuffle=True).split(X, y): # va generando los indices que corresponden a train y test en cada fold\n",
    "    X_train, X_test = X[train_index], X[test_index] # arma que es dato de entrenamiento y qué es dato de evaluación\n",
    "    y_train, y_test = y[train_index], y[test_index]     # idem con los targets\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                             max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, \n",
    "                             random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None) # Inicializamos nuevamente el modelo. max_iter es la cantidad de iteraciones maximas del algoritmo de optimizacion de parametros antes de detenerse.\n",
    "    clf.fit(X_train, y_train) # Ajustamos el modelo con los datos de entrenamiento\n",
    "\n",
    "    probas_test = clf.predict_proba(X_test)  # probabilidades con datos de evaluación\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probas_test[:,1]) # para tener curva ROC con datos de entrenamiento\n",
    "    auc_test = roc_auc_score(y_test, probas_test[:,1]) #  AUC con datos de evaluación\n",
    "\n",
    "    auc_values.append(auc_test)\n",
    "    scores = np.concatenate((scores,probas_test[:,1]),axis=0)\n",
    "    indices = np.concatenate((indices,test_index),axis=0)\n",
    "\n",
    "print(\"Estos son los valores AUC para cada fold:\")\n",
    "print(auc_values)\n",
    "print(\"Estos es el promedio de todos los AUC:\")\n",
    "print(np.mean(auc_values))\n",
    "print(\"Estos son las probabilidades para cada sample:\")\n",
    "print(scores)\n",
    "print(\"Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\")\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWXRO0TiW9Rn",
    "outputId": "70c257a6-338a-45c2-da11-2cb6862b91cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9698694424290579, 0.9689956756275335)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pruebo con una regresion logistica así como viene de fábrica\n",
    "clf = LogisticRegression()  \n",
    "\n",
    "# ajusto el modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# armo el vector de predicciones.\n",
    "y_hat_test = clf.predict_proba(X_test)[:, 1]\n",
    "y_hat_train = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# evaluo el AUC\n",
    "roc_test = roc_auc_score(y_test, y_hat_test)\n",
    "roc_train = roc_auc_score(y_train, y_hat_train)\n",
    "roc_train, roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPLPx_p2dad9",
    "outputId": "5d7e3fd2-fd39-4e1f-8dfc-37f0caf0de25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estos son los valores AUC para cada fold:\n",
      "[0.9678783302447594, 0.9676318460045085, 0.9679762787955928, 0.9703648883099637, 0.9702855102831723]\n",
      "Estos es el promedio de todos los AUC:\n",
      "0.9688273707275993\n",
      "Estos son las probabilidades para cada sample:\n",
      "[0.00857938 0.0096776  0.00973871 ... 0.92342349 0.91992661 0.91535417]\n",
      "Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\n",
      "[1.0000e+00 6.0000e+00 7.0000e+00 ... 4.5824e+04 4.5826e+04 4.5833e+04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "auc_values = [] # aca es donde van a ir a parar los AUCs de cada fold\n",
    "scores = np.array([])     # aca es donde van a ir a parar los scores computados para todos los casos\n",
    "indices = np.array([])    # aca es donde van a ir a parar los indices correspondientes a las entradas de scores\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5, shuffle=True).split(X, y): # va generando los indices que corresponden a train y test en cada fold\n",
    "    X_train, X_test = X[train_index], X[test_index] # arma que es dato de entrenamiento y qué es dato de evaluación\n",
    "    y_train, y_test = y[train_index], y[test_index]     # idem con los targets\n",
    "\n",
    "    clf = clf # Inicializamos nuevamente el modelo. max_iter es la cantidad de iteraciones maximas del algoritmo de optimizacion de parametros antes de detenerse.\n",
    "    clf.fit(X_train, y_train) # Ajustamos el modelo con los datos de entrenamiento\n",
    "\n",
    "    probas_test = clf.predict_proba(X_test)  # probabilidades con datos de evaluación\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probas_test[:,1]) # para tener curva ROC con datos de entrenamiento\n",
    "    auc_test = roc_auc_score(y_test, probas_test[:,1]) #  AUC con datos de evaluación\n",
    "\n",
    "    auc_values.append(auc_test)\n",
    "    scores = np.concatenate((scores,probas_test[:,1]),axis=0)\n",
    "    indices = np.concatenate((indices,test_index),axis=0)\n",
    "\n",
    "print(\"Estos son los valores AUC para cada fold:\")\n",
    "print(auc_values)\n",
    "print(\"Estos es el promedio de todos los AUC:\")\n",
    "print(np.mean(auc_values))\n",
    "print(\"Estos son las probabilidades para cada sample:\")\n",
    "print(scores)\n",
    "print(\"Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\")\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKoB_B0UW-Ju",
    "outputId": "709d6084-d9c5-4507-e654-3e4f47b8280d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999906714599758, 0.9197929253844154)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pruebo con un arbol de decision así como viene de fábrica\n",
    "clf = DecisionTreeClassifier()  \n",
    "\n",
    "# ajusto el modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# armo el vector de predicciones.\n",
    "y_hat_test = clf.predict_proba(X_test)[:, 1]\n",
    "y_hat_train = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# evaluo el AUC\n",
    "roc_test = roc_auc_score(y_test, y_hat_test)\n",
    "roc_train = roc_auc_score(y_train, y_hat_train)\n",
    "roc_train, roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YcNC8brdiz9",
    "outputId": "c1cfc2d0-0684-496e-b943-1a7012a74fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estos son los valores AUC para cada fold:\n",
      "[0.9138342288192022, 0.918554131268401, 0.9210528822489633, 0.9184313250888301, 0.9182481376995093]\n",
      "Estos es el promedio de todos los AUC:\n",
      "0.9180241410249812\n",
      "Estos son las probabilidades para cada sample:\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\n",
      "[2.0000e+00 8.0000e+00 9.0000e+00 ... 4.5828e+04 4.5829e+04 4.5831e+04]\n"
     ]
    }
   ],
   "source": [
    "auc_values = [] # aca es donde van a ir a parar los AUCs de cada fold\n",
    "scores = np.array([])     # aca es donde van a ir a parar los scores computados para todos los casos\n",
    "indices = np.array([])    # aca es donde van a ir a parar los indices correspondientes a las entradas de scores\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5, shuffle=True).split(X, y): # va generando los indices que corresponden a train y test en cada fold\n",
    "    X_train, X_test = X[train_index], X[test_index] # arma que es dato de entrenamiento y qué es dato de evaluación\n",
    "    y_train, y_test = y[train_index], y[test_index]     # idem con los targets\n",
    "\n",
    "    clf = clf # Inicializamos nuevamente el modelo. max_iter es la cantidad de iteraciones maximas del algoritmo de optimizacion de parametros antes de detenerse.\n",
    "    clf.fit(X_train, y_train) # Ajustamos el modelo con los datos de entrenamiento\n",
    "\n",
    "    probas_test = clf.predict_proba(X_test)  # probabilidades con datos de evaluación\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probas_test[:,1]) # para tener curva ROC con datos de entrenamiento\n",
    "    auc_test = roc_auc_score(y_test, probas_test[:,1]) #  AUC con datos de evaluación\n",
    "\n",
    "    auc_values.append(auc_test)\n",
    "    scores = np.concatenate((scores,probas_test[:,1]),axis=0)\n",
    "    indices = np.concatenate((indices,test_index),axis=0)\n",
    "\n",
    "print(\"Estos son los valores AUC para cada fold:\")\n",
    "print(auc_values)\n",
    "print(\"Estos es el promedio de todos los AUC:\")\n",
    "print(np.mean(auc_values))\n",
    "print(\"Estos son las probabilidades para cada sample:\")\n",
    "print(scores)\n",
    "print(\"Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\")\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIeh_5NEX81Y",
    "outputId": "770dc68d-1964-4d49-9380-d664e4e1a0b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9712776023101439, 0.9724091075400302)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pruebo con una red de perceptrones multilayer así como viene de fábrica\n",
    "clf = MLPClassifier()  \n",
    "\n",
    "# ajusto el modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# armo el vector de predicciones.\n",
    "y_hat_test = clf.predict_proba(X_test)[:, 1]\n",
    "y_hat_train = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# evaluo el AUC\n",
    "roc_test = roc_auc_score(y_test, y_hat_test)\n",
    "roc_train = roc_auc_score(y_train, y_hat_train)\n",
    "roc_train, roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjQ1MDsEdjxT",
    "outputId": "232dce42-47ed-42a5-9fcd-8cebf4dafe4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estos son los valores AUC para cada fold:\n",
      "[0.9710992715779002, 0.9699487527375997, 0.9698373281945312, 0.9731044107795728, 0.9706249127422756]\n",
      "Estos es el promedio de todos los AUC:\n",
      "0.970922935206376\n",
      "Estos son las probabilidades para cada sample:\n",
      "[0.02054257 0.01615146 0.00775284 ... 0.83811484 0.77615284 0.89220482]\n",
      "Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\n",
      "[0.0000e+00 1.9000e+01 3.1000e+01 ... 4.5816e+04 4.5824e+04 4.5831e+04]\n"
     ]
    }
   ],
   "source": [
    "auc_values = [] # aca es donde van a ir a parar los AUCs de cada fold\n",
    "scores = np.array([])     # aca es donde van a ir a parar los scores computados para todos los casos\n",
    "indices = np.array([])    # aca es donde van a ir a parar los indices correspondientes a las entradas de scores\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5, shuffle=True).split(X, y): # va generando los indices que corresponden a train y test en cada fold\n",
    "    X_train, X_test = X[train_index], X[test_index] # arma que es dato de entrenamiento y qué es dato de evaluación\n",
    "    y_train, y_test = y[train_index], y[test_index]     # idem con los targets\n",
    "\n",
    "    clf = clf # Inicializamos nuevamente el modelo. max_iter es la cantidad de iteraciones maximas del algoritmo de optimizacion de parametros antes de detenerse.\n",
    "    clf.fit(X_train, y_train) # Ajustamos el modelo con los datos de entrenamiento\n",
    "\n",
    "    probas_test = clf.predict_proba(X_test)  # probabilidades con datos de evaluación\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probas_test[:,1]) # para tener curva ROC con datos de entrenamiento\n",
    "    auc_test = roc_auc_score(y_test, probas_test[:,1]) #  AUC con datos de evaluación\n",
    "\n",
    "    auc_values.append(auc_test)\n",
    "    scores = np.concatenate((scores,probas_test[:,1]),axis=0)\n",
    "    indices = np.concatenate((indices,test_index),axis=0)\n",
    "\n",
    "print(\"Estos son los valores AUC para cada fold:\")\n",
    "print(auc_values)\n",
    "print(\"Estos es el promedio de todos los AUC:\")\n",
    "print(np.mean(auc_values))\n",
    "print(\"Estos son las probabilidades para cada sample:\")\n",
    "print(scores)\n",
    "print(\"Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\")\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mMzaLtsUZkM"
   },
   "source": [
    "Por último, veo que el RandomForest es quien obtiene los mejores resultados. Aplicamos el modelo ya entrenado a los datos de test4alumnxs.csv y guardo el vector \"predicciones\" y lo descargo, tal como muestra el screenshot de más abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OoTxIzJLyj5",
    "outputId": "347b58bf-2ee1-45f9-b37d-1b2f26038846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11372"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df_test[columnas]) # cargo el dataset de testeo\n",
    "\n",
    "predicciones = clf_rf.predict_proba(X)[:, 1] # obtengo el vector de probabilidades\n",
    "predicciones.size\n",
    "# Controlo que el vector de probabilidades tenga el mismo largo que las filas de df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Typ2yv1Lq6wZ",
    "outputId": "d733cda8-e227-4b2b-b81e-4243e9694d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.03 0.04 ... 0.01 0.97 0.  ]\n"
     ]
    }
   ],
   "source": [
    "print(predicciones)\n",
    "\n",
    "# lo guardo en el espacio de trabajo de colab\n",
    "np.savetxt('predicciones.csv', predicciones, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qEcLIy7kQix8",
    "UgcWpCiBNbH3",
    "q9ADQN0ETpKJ"
   ],
   "name": "Resolución TP2 Labo de datos 2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
