{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de severidad de accidentes de tránsito\n",
    "\n",
    "\n",
    "\n",
    "1.   Tenemos un archivo con datos: train.csv el cual contiene información sobre accidentes de tránsito en EEUU y un archivo test4alumnxs.csv que tiene la misma info pero sin las etiquetas para Severity (más información abajo).\n",
    "2.   El objetivo es usar los datos para construir un modelo que prediga la severidad del accidente (columna 'Severity', donde 0 es baja severidad y 1 es alta severidad). Para esto, primero puedo usar los datos del archivo train.csv para ajustar los parámetros del modelo, ajustar los hiperparámetros, combinar los features para agregar nuevos, estandarizar los datos, etc. Al terminar esto, tendré un modelo entrenado en estos datos, y una idea de que tan bien funciona. Luego generaremos un vector de probabilidades sobre el test4alumnos.csv para tratar de predecir la severidad del accidente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9ADQN0ETpKJ"
   },
   "source": [
    "# Los datos\n",
    "Los datos corresponden a registros de accidentes de tránsito en EEUU entre 2016 y 2021.\n",
    "\n",
    "Las primeras dos columnas (\"unnamed\") no sirve nara nada y se pueden descartar. \n",
    "\n",
    "La columna 'Severity' contiene la severidad del accidente (0 significa baja, 1 significa alta)\n",
    "\n",
    "Luego tenemos la hora de comienzo y final del accidente, la latitud/longitud inicial y final del accidente (entre que valores queda delimitado), la distancia de camino afectada por el accidente, una descripción verbal hecha por un humano, número y nombre de la calle donde ocurrió, lado de la calle (izquierda o derecha), ciudad, condado, estado, código postal, huso horario, código de aeropuerto donde se encuentra la estación meterológica más cercana al accidente, hora en la cual se midió el clima,temperatura, temperatura del viento, humedad, presión, visibilidad, dirección del viento, condición climática (despejado, sol, nieve, etc), presencia de comodidades (\"amenities\") en la cercanía del accidente, presencia de loma de burro, presencia de un cruce, presencia de señal de ceder paso, presencia de unión de calles, presencia de cartel de no salida, presencia de vías de tren, presencia de rotonda, presencia de estación, presencia de signo de parar, presencia de moderadores de tráfico, presencia de señales de tránsito, presencia de calle en forma de U (\"loop\"), día u oscuridad de acuerdo a la salida del sol, día u oscuridad de acuerdo a la penumbra civil (si es o no necesario utilizar alumbramiento eléctrico), día u oscuridad de acuerdo a la penumbra náutica, día u oscuridad de acuerdo a la penumbra astronómica.\n",
    "\n",
    "No todos estos campos son necesariamente útiles, y tampoco no todos están en un formato numérico directamente utilizable (por ejemplo, hay strings en la parte de descripción del accidente). Será parte del trabajo decidir que features quedarse, que features sumar, y como extraer información relevante de los features más complejos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4YgPyZuLQ3T",
    "outputId": "f38c8d1c-35e1-46eb-f5a8-f24d243d9ace"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "drive.mount('/content/drive') # montamos el drive\n",
    "\n",
    "# cargamos el dataframe de entrenamiento y el dataframe de testeo\n",
    "# el dataframe de entrenamiento tiene toda la información, incluyendo la columna 'Severity' (severidad)\n",
    "# esta es la columna que vamos a entrenar el modelo para predecir: 0=severidad baja; 1=severidad alta.\n",
    "# en cambio, el dataframe de test no tiene esta columna: son los datos que usamos para generar la predicción que se entrega \n",
    "filename_train = '/content/drive/My Drive/LaboDatos2022/SegundaEjercitacion/train.csv' \n",
    "filename_test = '/content/drive/My Drive/LaboDatos2022/SegundaEjercitacion/test4alumnxs.csv' \n",
    "\n",
    "df_train = pd.read_csv(filename_train)\n",
    "df_test = pd.read_csv(filename_test)\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXWCS2FzY_SV",
    "outputId": "21ff2ec4-79ad-4b3d-8167-2af55960c284"
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XP2_ICKMVGqZ",
    "outputId": "e7fca806-f7b5-49de-b2d7-837828bb55eb"
   },
   "outputs": [],
   "source": [
    "df_train[\"Severity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como el dataset no parece tener un desbalance importante, sigo adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCSubQOJ_hpP",
    "outputId": "5fbfbd4a-417b-4a0f-b2fb-922c82025830"
   },
   "outputs": [],
   "source": [
    "df_train[\"Weather_Condition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9fdBIBu15Gb",
    "outputId": "54e28285-0502-43f6-cb08-36cf67740d2f"
   },
   "outputs": [],
   "source": [
    "# Agrego algunas columnas a train.csv y a test4alumnxs.csv para testear mis hipótesis:\n",
    "# 1) Los accidentes más severos son los que se producen en autopistas o carreteras de alta velocidad (por ejemplo, rutas nacionales).\n",
    "# 2) Los accidentes más severos contienen una advertencia del tipo \"blocked\", \"multi\" o \"closed road\" (u otras)\n",
    "# 3) Los accidentes más severos se producen de noche.\n",
    "# 4) Los accidentes más severos se producen en condiciones climatológicas desfavorables (lluvia, nieve, niebla, etc).\n",
    "def highway_or_road(a):\n",
    "    if \"highway\" in a.lower():\n",
    "        return True\n",
    "    elif \"hwy\" in a.lower():\n",
    "        return True\n",
    "    elif \"road\" in a.lower():\n",
    "      return True\n",
    "    elif \"rd\" in a.lower():\n",
    "      return True\n",
    "    elif \"route\" in a.lower():\n",
    "      return True\n",
    "    else:\n",
    "        return False\n",
    "df_train[\"Highway_or_road\"] = df_train[\"Street\"].apply(lambda x: highway_or_road(x))\n",
    "df_test[\"Highway_or_road\"] = df_test[\"Street\"].apply(lambda x: highway_or_road(x))\n",
    "\n",
    "def serious(a):\n",
    "    #if \"drive with caution\" in a.lower():\n",
    "        #return True\n",
    "    if \"closed\" in a.lower():\n",
    "        return True\n",
    "    elif \"blocked\" in a.lower():\n",
    "      return True\n",
    "    elif \"closure\" in a.lower():\n",
    "      return True\n",
    "    elif \"multi\" in a.lower():\n",
    "      return True\n",
    "    elif \"serious\" in a.lower():\n",
    "      return True\n",
    "    else:\n",
    "        return False\n",
    "df_train[\"Serious\"] = df_train[\"Description\"].apply(lambda x: serious(x))\n",
    "df_test[\"Serious\"] = df_test[\"Description\"].apply(lambda x: serious(x))\n",
    "\n",
    "def night(a):\n",
    "  if \"Night\" in a.lower():\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "df_train[\"Night\"] = df_train[\"Civil_Twilight\"].apply(lambda x: night(x))\n",
    "df_test[\"Night\"] = df_test[\"Civil_Twilight\"].apply(lambda x: night(x))\n",
    "\n",
    "def adverse_weather(a):\n",
    "  if \"rain\" in a.lower():\n",
    "    return True\n",
    "  elif \"snow\" in a.lower():\n",
    "    return True\n",
    "  elif \"fog\" in a.lower():\n",
    "    return True\n",
    "  elif \"smoke\" in a.lower():\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "df_train[\"Adverse_Weather\"] = df_train[\"Weather_Condition\"].apply(lambda x: adverse_weather(x))\n",
    "df_test[\"Adverse_Weather\"] = df_test[\"Weather_Condition\"].apply(lambda x: adverse_weather(x))\n",
    "\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOovUCx56wYH",
    "outputId": "f6e818b7-b5fb-40ba-c9ef-98ca26af923d"
   },
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHJKbQHB64R-",
    "outputId": "493262c8-5a17-4cdd-cba5-7ca8cecf5b0a"
   },
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "id": "6EWy_VCgEN-W",
    "outputId": "37d999e7-8144-4760-d451-7f6cd7b1a0b0"
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z83OloICT0Ug"
   },
   "source": [
    "Luego, sacamos el vector de etiquetas (severidad).\n",
    "\n",
    "En este modelo vamos a usar el subconjunto de features que corresponde a variables climáticas: temperatura, temperatura del viento, humedad, presión, visibilidad, velocidad del viento y precipitación así como otras correspondientes al contexto del accidente (si era un cruce de calles, si ocurrió en autopista, si el clima era adverso, etc.).\n",
    "\n",
    "Con esto armamos la matriz X. Luego, separamos un 70%/30% para train y test del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWiWcD7eLtT-"
   },
   "outputs": [],
   "source": [
    "y = np.array(df_train['Severity']) # armo el vector de etiquetas\n",
    "\n",
    "# vamos a entrenar un modelo con estas variables\n",
    "columnas = ['Temperature(F)', 'Wind_Chill(F)', 'Distance(mi)', 'Stop', 'Humidity(%)','Junction','Crossing', \"Highway_or_road\", \"Serious\", \"Night\", \"Adverse_Weather\",'Traffic_Signal', 'Traffic_Calming','Pressure(in)','Visibility(mi)','Wind_Speed(mph)','Precipitation(in)']\n",
    "\n",
    "# extraigo la matriz de features X\n",
    "X = np.array(df_train[columnas])\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2MyvbDWW6KQ",
    "outputId": "c594cd28-b59b-4868-c5ef-2530ae0b6dc8"
   },
   "outputs": [],
   "source": [
    "# pruebo con un random forest así como viene de fábrica\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                             max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, \n",
    "                             random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)  \n",
    "\n",
    "# ajusto el modelo\n",
    "clf_rf.fit(X_train, y_train) #Como veo que es el mejor modelo, lo nombro de diferente manera así puedo luego armar el vector de etiquetas.\n",
    "\n",
    "# armo el vector de predicciones.\n",
    "y_hat_test = clf_rf.predict_proba(X_test)[:, 1]\n",
    "y_hat_train = clf_rf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# evaluo el AUC\n",
    "roc_test = roc_auc_score(y_test, y_hat_test)\n",
    "roc_train = roc_auc_score(y_train, y_hat_train)\n",
    "roc_train, roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atvDe3ppYMdz",
    "outputId": "556c7221-3bb0-4f68-9f15-718cc8168be4"
   },
   "outputs": [],
   "source": [
    "auc_values = [] # aca es donde van a ir a parar los AUCs de cada fold\n",
    "scores = np.array([])     # aca es donde van a ir a parar los scores computados para todos los casos\n",
    "indices = np.array([])    # aca es donde van a ir a parar los indices correspondientes a las entradas de scores\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5, shuffle=True).split(X, y): # va generando los indices que corresponden a train y test en cada fold\n",
    "    X_train, X_test = X[train_index], X[test_index] # arma que es dato de entrenamiento y qué es dato de evaluación\n",
    "    y_train, y_test = y[train_index], y[test_index]     # idem con los targets\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                             max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, \n",
    "                             random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None) # Inicializamos nuevamente el modelo. max_iter es la cantidad de iteraciones maximas del algoritmo de optimizacion de parametros antes de detenerse.\n",
    "    clf.fit(X_train, y_train) # Ajustamos el modelo con los datos de entrenamiento\n",
    "\n",
    "    probas_test = clf.predict_proba(X_test)  # probabilidades con datos de evaluación\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probas_test[:,1]) # para tener curva ROC con datos de entrenamiento\n",
    "    auc_test = roc_auc_score(y_test, probas_test[:,1]) #  AUC con datos de evaluación\n",
    "\n",
    "    auc_values.append(auc_test)\n",
    "    scores = np.concatenate((scores,probas_test[:,1]),axis=0)\n",
    "    indices = np.concatenate((indices,test_index),axis=0)\n",
    "\n",
    "print(\"Estos son los valores AUC para cada fold:\")\n",
    "print(auc_values)\n",
    "print(\"Estos es el promedio de todos los AUC:\")\n",
    "print(np.mean(auc_values))\n",
    "print(\"Estos son las probabilidades para cada sample:\")\n",
    "print(scores)\n",
    "print(\"Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\")\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWXRO0TiW9Rn",
    "outputId": "70c257a6-338a-45c2-da11-2cb6862b91cf"
   },
   "outputs": [],
   "source": [
    "# pruebo con una regresion logistica así como viene de fábrica\n",
    "clf = LogisticRegression()  \n",
    "\n",
    "# ajusto el modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# armo el vector de predicciones.\n",
    "y_hat_test = clf.predict_proba(X_test)[:, 1]\n",
    "y_hat_train = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# evaluo el AUC\n",
    "roc_test = roc_auc_score(y_test, y_hat_test)\n",
    "roc_train = roc_auc_score(y_train, y_hat_train)\n",
    "roc_train, roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPLPx_p2dad9",
    "outputId": "5d7e3fd2-fd39-4e1f-8dfc-37f0caf0de25"
   },
   "outputs": [],
   "source": [
    "auc_values = [] # aca es donde van a ir a parar los AUCs de cada fold\n",
    "scores = np.array([])     # aca es donde van a ir a parar los scores computados para todos los casos\n",
    "indices = np.array([])    # aca es donde van a ir a parar los indices correspondientes a las entradas de scores\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5, shuffle=True).split(X, y): # va generando los indices que corresponden a train y test en cada fold\n",
    "    X_train, X_test = X[train_index], X[test_index] # arma que es dato de entrenamiento y qué es dato de evaluación\n",
    "    y_train, y_test = y[train_index], y[test_index]     # idem con los targets\n",
    "\n",
    "    clf = clf # Inicializamos nuevamente el modelo. max_iter es la cantidad de iteraciones maximas del algoritmo de optimizacion de parametros antes de detenerse.\n",
    "    clf.fit(X_train, y_train) # Ajustamos el modelo con los datos de entrenamiento\n",
    "\n",
    "    probas_test = clf.predict_proba(X_test)  # probabilidades con datos de evaluación\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probas_test[:,1]) # para tener curva ROC con datos de entrenamiento\n",
    "    auc_test = roc_auc_score(y_test, probas_test[:,1]) #  AUC con datos de evaluación\n",
    "\n",
    "    auc_values.append(auc_test)\n",
    "    scores = np.concatenate((scores,probas_test[:,1]),axis=0)\n",
    "    indices = np.concatenate((indices,test_index),axis=0)\n",
    "\n",
    "print(\"Estos son los valores AUC para cada fold:\")\n",
    "print(auc_values)\n",
    "print(\"Estos es el promedio de todos los AUC:\")\n",
    "print(np.mean(auc_values))\n",
    "print(\"Estos son las probabilidades para cada sample:\")\n",
    "print(scores)\n",
    "print(\"Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\")\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKoB_B0UW-Ju",
    "outputId": "709d6084-d9c5-4507-e654-3e4f47b8280d"
   },
   "outputs": [],
   "source": [
    "# pruebo con un arbol de decision así como viene de fábrica\n",
    "clf = DecisionTreeClassifier()  \n",
    "\n",
    "# ajusto el modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# armo el vector de predicciones.\n",
    "y_hat_test = clf.predict_proba(X_test)[:, 1]\n",
    "y_hat_train = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# evaluo el AUC\n",
    "roc_test = roc_auc_score(y_test, y_hat_test)\n",
    "roc_train = roc_auc_score(y_train, y_hat_train)\n",
    "roc_train, roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YcNC8brdiz9",
    "outputId": "c1cfc2d0-0684-496e-b943-1a7012a74fc1"
   },
   "outputs": [],
   "source": [
    "auc_values = [] # aca es donde van a ir a parar los AUCs de cada fold\n",
    "scores = np.array([])     # aca es donde van a ir a parar los scores computados para todos los casos\n",
    "indices = np.array([])    # aca es donde van a ir a parar los indices correspondientes a las entradas de scores\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5, shuffle=True).split(X, y): # va generando los indices que corresponden a train y test en cada fold\n",
    "    X_train, X_test = X[train_index], X[test_index] # arma que es dato de entrenamiento y qué es dato de evaluación\n",
    "    y_train, y_test = y[train_index], y[test_index]     # idem con los targets\n",
    "\n",
    "    clf = clf # Inicializamos nuevamente el modelo. max_iter es la cantidad de iteraciones maximas del algoritmo de optimizacion de parametros antes de detenerse.\n",
    "    clf.fit(X_train, y_train) # Ajustamos el modelo con los datos de entrenamiento\n",
    "\n",
    "    probas_test = clf.predict_proba(X_test)  # probabilidades con datos de evaluación\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probas_test[:,1]) # para tener curva ROC con datos de entrenamiento\n",
    "    auc_test = roc_auc_score(y_test, probas_test[:,1]) #  AUC con datos de evaluación\n",
    "\n",
    "    auc_values.append(auc_test)\n",
    "    scores = np.concatenate((scores,probas_test[:,1]),axis=0)\n",
    "    indices = np.concatenate((indices,test_index),axis=0)\n",
    "\n",
    "print(\"Estos son los valores AUC para cada fold:\")\n",
    "print(auc_values)\n",
    "print(\"Estos es el promedio de todos los AUC:\")\n",
    "print(np.mean(auc_values))\n",
    "print(\"Estos son las probabilidades para cada sample:\")\n",
    "print(scores)\n",
    "print(\"Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\")\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIeh_5NEX81Y",
    "outputId": "770dc68d-1964-4d49-9380-d664e4e1a0b9"
   },
   "outputs": [],
   "source": [
    "# pruebo con una red de perceptrones multilayer así como viene de fábrica\n",
    "clf = MLPClassifier()  \n",
    "\n",
    "# ajusto el modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# armo el vector de predicciones.\n",
    "y_hat_test = clf.predict_proba(X_test)[:, 1]\n",
    "y_hat_train = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# evaluo el AUC\n",
    "roc_test = roc_auc_score(y_test, y_hat_test)\n",
    "roc_train = roc_auc_score(y_train, y_hat_train)\n",
    "roc_train, roc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjQ1MDsEdjxT",
    "outputId": "232dce42-47ed-42a5-9fcd-8cebf4dafe4f"
   },
   "outputs": [],
   "source": [
    "auc_values = [] # aca es donde van a ir a parar los AUCs de cada fold\n",
    "scores = np.array([])     # aca es donde van a ir a parar los scores computados para todos los casos\n",
    "indices = np.array([])    # aca es donde van a ir a parar los indices correspondientes a las entradas de scores\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5, shuffle=True).split(X, y): # va generando los indices que corresponden a train y test en cada fold\n",
    "    X_train, X_test = X[train_index], X[test_index] # arma que es dato de entrenamiento y qué es dato de evaluación\n",
    "    y_train, y_test = y[train_index], y[test_index]     # idem con los targets\n",
    "\n",
    "    clf = clf # Inicializamos nuevamente el modelo. max_iter es la cantidad de iteraciones maximas del algoritmo de optimizacion de parametros antes de detenerse.\n",
    "    clf.fit(X_train, y_train) # Ajustamos el modelo con los datos de entrenamiento\n",
    "\n",
    "    probas_test = clf.predict_proba(X_test)  # probabilidades con datos de evaluación\n",
    "    fpr_test, tpr_test, thresholds_test = roc_curve(y_test, probas_test[:,1]) # para tener curva ROC con datos de entrenamiento\n",
    "    auc_test = roc_auc_score(y_test, probas_test[:,1]) #  AUC con datos de evaluación\n",
    "\n",
    "    auc_values.append(auc_test)\n",
    "    scores = np.concatenate((scores,probas_test[:,1]),axis=0)\n",
    "    indices = np.concatenate((indices,test_index),axis=0)\n",
    "\n",
    "print(\"Estos son los valores AUC para cada fold:\")\n",
    "print(auc_values)\n",
    "print(\"Estos es el promedio de todos los AUC:\")\n",
    "print(np.mean(auc_values))\n",
    "print(\"Estos son las probabilidades para cada sample:\")\n",
    "print(scores)\n",
    "print(\"Esta es la forma en que quedaron ordenados las entradas del vector anterior (indices):\")\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mMzaLtsUZkM"
   },
   "source": [
    "Por último, veo que el RandomForest es quien obtiene los mejores resultados. Aplicamos el modelo ya entrenado a los datos de test4alumnxs.csv y guardo el vector \"predicciones\" y lo descargo, tal como muestra el screenshot de más abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OoTxIzJLyj5",
    "outputId": "347b58bf-2ee1-45f9-b37d-1b2f26038846"
   },
   "outputs": [],
   "source": [
    "X = np.array(df_test[columnas]) # cargo el dataset de testeo\n",
    "\n",
    "predicciones = clf_rf.predict_proba(X)[:, 1] # obtengo el vector de probabilidades\n",
    "predicciones.size\n",
    "# Controlo que el vector de probabilidades tenga el mismo largo que las filas de df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Typ2yv1Lq6wZ",
    "outputId": "d733cda8-e227-4b2b-b81e-4243e9694d17"
   },
   "outputs": [],
   "source": [
    "print(predicciones)\n",
    "\n",
    "# lo guardo en el espacio de trabajo de colab\n",
    "np.savetxt('predicciones.csv', predicciones, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "qEcLIy7kQix8",
    "UgcWpCiBNbH3",
    "q9ADQN0ETpKJ"
   ],
   "name": "Resolución TP2 Labo de datos 2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
